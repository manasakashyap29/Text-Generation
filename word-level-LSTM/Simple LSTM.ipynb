{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the libraries \n",
    "The idea is to implement a LSTM model to generate jokes using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input\n",
    "Read the input file and convert all characters to lowercase. This reduces the vocabulary size for the model to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the file and convert all characters to lowercase\n",
    "filename = \"shortjokes.csv\"\n",
    "text = open(filename).read().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping\n",
    "Create a list of unique characters read from the input file\n",
    "<br>\n",
    "Create a mapping from character to index and vice-versa\n",
    "<br>\n",
    "no_of_chars = total number of characters in the input file\n",
    "<br>\n",
    "vocab_size = total number of unique characters in the input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text))) #list of distinct characters\n",
    "#mapping\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "no_of_chars = len(text)\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Split the text into sequences of 100 characters<br>\n",
    "Each training pattern consists of 50 time steps of one character (X) followed by one character output (y)\n",
    "Example:\n",
    "Iteration #1:<br>\n",
    "Input : HAPPI<br>\n",
    "Output: N<br>\n",
    "Iteration #2:<br>\n",
    "Input: APPIN<br>\n",
    "Output : E<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "step = 100\n",
    "X_data = []\n",
    "Y= []\n",
    "for i in range(0, n_chars - seq_length, step):\n",
    "    input = text[i:i + seq_length] \n",
    "    output = raw_text[i + seq_length]\n",
    "    X_data.append([char_to_int[char] for char in input])\n",
    "    Y.append(char_to_int[output])\n",
    "no_of_patterns = len(X_data)\n",
    "# reshape X to be [samples, time steps, features] as LSTM requires 3D\n",
    "X = numpy.reshape(X_data, (no_of_patterns, seq_length, 1)) #vector encodings\n",
    "X = X / float(vocab_size) #normalize input\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model\n",
    "The model defined is a LSTM with 128 hidden units. The model is a single layer LSTM with 128 units and a dropout layer with probability 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The best weights of the model are stored in a file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"best_weights_1.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "# fit the model\n",
    "model.fit(X, y, epochs=50, batch_size=64, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"best_weights_1.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of text\n",
    "To generate text, we pick a random seed and the number of characters, we want the model to generate.\n",
    "The seed sequence serves as an input to the model, it then generates the next character which it assumes to be most likely to appear and then the seed is updated by removing the ifrst character and adding the generated character in the end, essentially like sliding a window of fixed length one character at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed,chars):\n",
    "# pick a random seed\n",
    "    for k in range(seed):\n",
    "        start = numpy.random.randint(0, len(X)-1)\n",
    "        start_seed = X_data[start]\n",
    "        print (\"\\\"\",''.join([int_to_char[value] for value in start_seed]),\"\\\"\")\n",
    "        # generate characters\n",
    "        for i in range(chars):\n",
    "            x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "            x = x / float(vocab_size)\n",
    "            prediction = model.predict(x, verbose=0)\n",
    "            index = numpy.argmax(prediction)\n",
    "            result = int_to_char[index]\n",
    "            sys.stdout.write(result)\n",
    "            start_seed.append(index)\n",
    "            start_seed = start_seed[1:len(start_seed)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(100,50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
